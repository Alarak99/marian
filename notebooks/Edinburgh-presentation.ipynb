{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Attention-based Neural Machine Translation Models as Feature Functions in Moses\n",
    "\n",
    "</br></br>\n",
    "##### Marcin Junczys-Dowmunt, Tomasz Dwojak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Neural Machine Translation by Jointly Learning to Align and Translate**\n",
    "\n",
    "Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio\n",
    "\n",
    "* http://arxiv.org/abs/1409.0473\n",
    "* http://arxiv.org/pdf/1409.0473v6.pdf\n",
    "\n",
    "And an open source implementation in GroundHog:\n",
    "\n",
    "https://github.com/lisa-groundhog/GroundHog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Implementation problems\n",
    "\n",
    "* Standard Moses FF-interface unusable \n",
    "* Results in millions of queries to GPU\n",
    "* **No. of GPU queries is proportional to no. of hypotheses**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Possible Solution:\n",
    "\n",
    "* Add step **before** hypothesis expansion that collects all hypotheses and possible extensions\n",
    "* Pre-calculate probabilities for all possible probabilities:\n",
    "   * Assemble all state vectors for hypothesis in stack into one matrix (duplicated by number of extensions per hypothesis)\n",
    "   * Perform **one step** per target word position\n",
    "* Treat pre-calculated values like a static language model\n",
    "* Query within normal FF-interface\n",
    "* **No. of GPU queries is proportional to no. of stacks** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## First attempt (MTM2015): Embedding python interpreter in C++\n",
    "\n",
    "* https://github.com/emjotde/mosesdecoder/blob/oldstuff/moses/FF/NMT/NMT_Wrapper.cpp#L122-L161\n",
    "* Slow\n",
    "* Instable\n",
    "* Would not scale to multiple GPUs or Multi-Threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## But seems to work!\n",
    "\n",
    "System trained on IWSLT 2015 data (en-de), evaluated on Test-2013.\n",
    "\n",
    "</br>\n",
    "\n",
    "\n",
    "### Stand-alone\n",
    "* 21.5 (Vanilla Moses)\n",
    "* 25.6 (our Moses setup)\n",
    "* 25.8 (3-ensemble Groundhog NMT): \n",
    "\n",
    "</br>\n",
    "### Combinations:\n",
    "* 27.2 (rescoring a 1000-best list)\n",
    "* 28.3 (Moses with NMT-FF with Stack-Size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Re-implementation\n",
    "## Python Numpy (to understand what's going on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_0_dec_approx_embdr (30001, 620)\n",
      "b_0_dec_initializer_0 (1000,)\n",
      "b_0_dec_hid_readout_0 (1000,)\n",
      "W_0_dec_repr_readout (2000, 1000)\n",
      "b_dec_deep_softmax (30001,)\n",
      "D_dec_transition_0 (1000, 1)\n",
      "B_dec_transition_0 (1000, 1000)\n",
      "R_dec_transition_0 (1000, 1000)\n",
      "W_back_enc_transition_0 (1000, 1000)\n",
      "R_back_enc_transition_0 (1000, 1000)\n",
      "R_enc_transition_0 (1000, 1000)\n",
      "W_0_dec_update_embdr_0 (620, 1000)\n",
      "W_0_dec_initializer_0 (1000, 1000)\n",
      "W_0_dec_input_embdr_0 (620, 1000)\n",
      "b_0_dec_input_embdr_0 (1000,)\n",
      "G_dec_transition_0 (1000, 1000)\n",
      "W_0_back_enc_reset_embdr_0 (620, 1000)\n",
      "W_0_dec_dec_updater_0 (2000, 1000)\n",
      "G_enc_transition_0 (1000, 1000)\n",
      "W_0_enc_input_embdr_0 (620, 1000)\n",
      "W_dec_transition_0 (1000, 1000)\n",
      "W2_dec_deep_softmax (620, 30001)\n",
      "W_enc_transition_0 (1000, 1000)\n",
      "b_0_enc_approx_embdr (620,)\n",
      "W_0_dec_dec_inputter_0 (2000, 1000)\n",
      "W_0_enc_reset_embdr_0 (620, 1000)\n",
      "b_0_back_enc_input_embdr_0 (1000,)\n",
      "W_0_dec_reset_embdr_0 (620, 1000)\n",
      "W_0_dec_prev_readout_0 (620, 1000)\n",
      "W_0_dec_hid_readout_0 (1000, 1000)\n",
      "W_0_dec_dec_reseter_0 (2000, 1000)\n",
      "G_back_enc_transition_0 (1000, 1000)\n",
      "W1_dec_deep_softmax (500, 620)\n",
      "W_0_back_enc_input_embdr_0 (620, 1000)\n",
      "A_dec_transition_0 (2000, 1000)\n",
      "b_0_dec_approx_embdr (620,)\n",
      "W_0_enc_update_embdr_0 (620, 1000)\n",
      "b_0_enc_input_embdr_0 (1000,)\n",
      "W_0_enc_approx_embdr (30001, 620)\n",
      "W_0_back_enc_update_embdr_0 (620, 1000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"/home/marcinj/Badania/best_nmt/search_model.npz\")\n",
    "for key in data:\n",
    "    print(key, data[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Common\n",
    "\n",
    "* $\\overline{E}$ - `W_0_enc_approx_embdr` - the same for both directions, shape ${m \\times K_x}$, where $m = 620$ i $K_x = 30001$\n",
    "* $\\overline{b}_{\\bar{E}}$ - `b_0_enc_approx_embdr`, shape $m \\times 1$, bias for `W_enc_approx_embdr`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Forward\n",
    "\n",
    "* $\\overrightarrow{W}$ - `W_0_enc_input_embdr_0` - weights for 0th hidden layer, left-to-right, shape $n\\times m$, where $n=1000$\n",
    "* $\\overrightarrow{W}_z$ - `W_0_enc_update_embdr_0` - GRU update, shape $n\\times m$\n",
    "* $\\overrightarrow{W}_r$ - `W_0_enc_reset_embdr_0` - GRU reset, shape $n\\times m$\n",
    "* $\\overrightarrow{U}$ - `W_enc_transition_0`, shape $n \\times n$\n",
    "* $\\overrightarrow{U}_z$ - `G_enc_transition_0`, shape $n \\times n$\n",
    "* $\\overrightarrow{U}_r$ - `R_enc_transition_0`, shape $n \\times n$\n",
    "* $\\overrightarrow{b}_{\\overrightarrow{W}}$ - `b_0_enc_input_embdr_0`, shape $n \\times 1$, bias for `W_0_enc_input_embdr_0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Backward\n",
    "Analoguous, with `back` interfix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Calculations\n",
    "\n",
    "Formulae taken from Bahdanau *et. al* (2014) with re-added biases:\n",
    "\n",
    "$$\n",
    "\\renewcommand{\\ora}[1]{\\overrightarrow{#1}}\n",
    "\\renewcommand{\\ola}[1]{\\overleftarrow{#1}}\n",
    "\\ora{h}_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "(1 - \\ora{z}_i) \\circ \\ora{h}_{i-1} + \\ora{z}_i \\circ \\ora{\\underline{h}}_i & \\mathrm{, if } i > 0 \\\\\n",
    "0 & \\mathrm{, if } i = 0 \n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\ora{\\underline{h}}_i &=& \\tanh\\left(\\ora{W}(\\overline{E}x_i+\\overline{b}) + \\ora{b}_{\\ora{W}} +\\ora{U}\\left[\\ora{r}_i \\circ \\ora{h}_{i-1}\\right]\\right)\\\\\n",
    "\\ora{z_i} &=& \\sigma\\left(\\ora{W}_z(\\overline{E}x_i+\\overline{b})+\\ora{U}_z\\ora{h}_{i-1}\\right)\\\\\n",
    "\\ora{r_i} &=& \\sigma\\left(\\ora{W}_r(\\overline{E}x_i+\\overline{b})+\\ora{U}_r\\ora{h}_{i-1}\\right)\\\\\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "The other directions works similarly, we only change the direction of the arrow. Implementation-wise, we reverse the input sequence, use the matrices for the other direction and reverse the result row-wise. Then we get:\n",
    "\n",
    "$$\n",
    "h_i = \\left[\n",
    "\\begin{array}{c}\n",
    "\\ora{h}_i \\\\\n",
    "\\ola{h}_i\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Embeddings\n",
    "\n",
    "* $E$ - `W_0_dec_approx_embdr`, embeddings dla wyj≈õcia, rozmiar $m \\times K_y$\n",
    "* $b$ - `b_0_dec_approx_embdr`, bias dla embeddings, rozmiar $m \\times 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### RNN and GRU\n",
    "\n",
    "* $W_s$ - `W_0_dec_initializer_0`, weight matrix used to calculate the initial state of the decoder\n",
    "* $b_{W_s}$ - `b_0_dec_initializer_0`, bias for the initial state weight matrix\n",
    "* $W$ - `W_0_dec_input_embdr_0` - shape $n\\times m$\n",
    "* $b_W$ - `b_0_dec_input_embdr_0`, bias\n",
    "* $W_z$ - `W_0_dec_update_embdr_0` -GRU update, shape $n\\times m$\n",
    "* $W_r$ - `W_0_dec_reset_embdr_0` - GRU reset, shape $n\\times m$\n",
    "* $U$ - `W_dec_transition_0`, shape $n \\times n$\n",
    "* $U_z$ - `G_dec_transition_0`, shape $n \\times n$\n",
    "* $U_r$ - `R_dec_transition_0`, shape $n \\times n$\n",
    "* $C$ - `W_0_dec_dec_inputter_0`, shape $n \\times 2n$\n",
    "* $C_z$ - `W_0_dec_dec_updater_0`, shape $n \\times 2n$\n",
    "* $C_r$ - `W_0_dec_dec_reseter_0`, shape $n \\times 2n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Alignment model\n",
    "\n",
    "$n^\\prime=1000$ number of neurons in the alignment model, \n",
    "\n",
    "* $v_\\alpha$ - `D_dec_transition_0`, shape $n^\\prime \\times 1$\n",
    "* $W_\\alpha$ - `B_dec_transition_0`, shape $n^\\prime \\times n$\n",
    "* $U_\\alpha$ - `A_dec_transition_0`, shape $n^\\prime \\times 2n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Softmax\n",
    "\n",
    "$l = 500$, size of hidden softmax layer, and $W_o = W_o^{(2)}W_o^{(1)}$\n",
    "\n",
    "* $W_{o}^{(1)}$ - `W1_dec_deep_softmax`, shape $m\\times l$\n",
    "* $W_{o}^{(2)}$ - `W2_dec_deep_softmax`, shape $K_y\\times m$\n",
    "* $b_{W_o}$ - `b_dec_deep_softmax`, bias, shape $K_y\\times 1$.\n",
    "* $U_o$ - `W_0_dec_hid_readout_0`, shape $2l \\times 2l$\n",
    "* $b_{U_o}$ `b_0_dec_hid_readout_0`, shape $2l \\times 1$\n",
    "* $V_o$ - `W_0_dec_prev_readout_0`, $2l \\times m$\n",
    "* $C_o$ - `W_0_dec_repr_readout_0`, shape $2l \\times 2n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Calculations\n",
    "\n",
    "### GRU\n",
    "\n",
    "$$\n",
    "s_i = (1-z_i) \\circ s_{i-1} + z_i \\circ \\tilde{s}_i \\qquad s_0 = \\tanh\\left(W_s\\ola{h}_1 + b_{W_s}\\right)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\tilde{s_i} &=& \\tanh\\left(W(Ey_i+b) + b_W + U \\left[r_i \\circ s_{i-1}\\right] +Cc_i\\right) \\\\\n",
    "z_i &=& \\sigma\\left(W_z(Ey_i+b)+U_zs_{i-1} + C_zc_i \\right)\\\\\n",
    "r_i &=& \\sigma\\left(W_r(Ey_i+b)+U_rs_{i-1} + C_rc_i \\right)\\\\\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Attention Model\n",
    "\n",
    "Attention score is calculated as:\n",
    "\n",
    "$$\n",
    "c_i = \\sum_{j=1}^{T_x} \\alpha_{ij}h_j\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \n",
    "\\begin{eqnarray}\n",
    "\\alpha_{ij} &=& \\frac{\\exp(e_{ij})}{\\sum_{k=1}^{T_x}\\exp(e_{ik})} \\\\ \n",
    "e_{ij} &=& v_\\alpha^T \\tanh\\left(W_{\\alpha}s_{i-1} + U_{\\alpha}h_j\\right) \n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Deep Softmax\n",
    "And deep softmax (here $W_o = W_o^{(2)}W_o^{(1)}$):\n",
    "\n",
    "$$\n",
    "p(y_i|s_{i-1},y_{i-1},c_i) = \\textrm{softmax}\\left(y_i^T\\left(W_ot_i + b_o\\right)\\right) \n",
    "$$\n",
    "\n",
    "where ($l = 500$)\n",
    "\n",
    "$$\n",
    "t_i = \\left[\\max \\left\\{ \\tilde{t}_{i,2j-1},\\tilde{t}_{i,2j} \\right\\}\\right]_{j=1,\\ldots,l}^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tilde{t}_i = U_os_{i-1}+b_{U_o}+V_o(Ey_{i-1} + b)+C_oc_i \n",
    "$$\n",
    "\n",
    "where $y_0$ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pure Numpy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#%%writefile bahdanau.py\n",
    "\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "def logit(X):\n",
    "    return 1.0 / (1.0 + np.exp(-X))\n",
    "\n",
    "def softmax(X, ax=0):\n",
    "    expX = np.exp(X)\n",
    "    expXsum = np.sum(expX, axis=ax)\n",
    "    return (expX / expXsum)\n",
    "\n",
    "def batchAndMask(sents):\n",
    "    maxLength = max(len(s) for s in sents)\n",
    "    sentsPadded = [np.pad(np.copy(s), (0, maxLength-len(s)), mode=\"constant\") \n",
    "                   for s in sents]\n",
    "    batch = np.vstack(sentsPadded)\n",
    "    mask = batch != 0\n",
    "    return batch, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#%%writefile -a bahdanau.py\n",
    "\n",
    "class Encoder:\n",
    "    class Embeddings:\n",
    "        def __init__(self, data):\n",
    "            self.E  = data[\"W_0_enc_approx_embdr\"]\n",
    "            self.EB = data[\"b_0_enc_approx_embdr\"].T\n",
    "\n",
    "        def Lookup(self, i):\n",
    "            return self.E[i] + self.EB\n",
    "    \n",
    "    class RNN:\n",
    "        def __init__(self, data):\n",
    "            self.W   = data[\"W\"]\n",
    "            self.B   = data[\"B\"]\n",
    "            self.U   = data[\"U\"]\n",
    "            self.Wz  = data[\"Wz\"]\n",
    "            self.Uz  = data[\"Uz\"]\n",
    "            self.Wr  = data[\"Wr\"]\n",
    "            self.Ur  = data[\"Ur\"]\n",
    "\n",
    "        def InitializeState(self, batchSize=1):\n",
    "            H0 = np.zeros(1000 * batchSize).reshape(batchSize, 1000)\n",
    "            return H0\n",
    "        \n",
    "        def GetNextState(self, embd, prevState):\n",
    "            Zi  = logit(embd.dot(self.Wz) + prevState.dot(self.Uz))\n",
    "            Ri  = logit(embd.dot(self.Wr) + prevState.dot(self.Ur))\n",
    "            Hi_ = np.tanh(embd.dot(self.W) + self.B + (Ri * prevState).dot(self.U)) \n",
    "            Hi  = (1.0 - Zi) * prevState + Zi * Hi_\n",
    "            return Hi\n",
    "        \n",
    "        def GetContext(self, embeddings):\n",
    "            states = []\n",
    "            prevState = self.InitializeState()\n",
    "            for embd in embeddings:\n",
    "                state = self.GetNextState(embd, prevState)\n",
    "                states.append(state)\n",
    "                prevState = state\n",
    "            return states\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.embeddings = self.Embeddings(data)\n",
    "        \n",
    "        fW = dict()\n",
    "        fW[\"W\"] = data[\"W_0_enc_input_embdr_0\"]\n",
    "        fW[\"B\"] = data[\"b_0_enc_input_embdr_0\"].T\n",
    "        fW[\"U\"] = data[\"W_enc_transition_0\"]\n",
    "        fW[\"Wz\"] = data[\"W_0_enc_update_embdr_0\"]\n",
    "        fW[\"Uz\"] = data[\"G_enc_transition_0\"]\n",
    "        fW[\"Wr\"] = data[\"W_0_enc_reset_embdr_0\"]\n",
    "        fW[\"Ur\"] = data[\"R_enc_transition_0\"]\n",
    "\n",
    "        bW = dict()\n",
    "        bW[\"W\"] = data[\"W_0_back_enc_input_embdr_0\"]\n",
    "        bW[\"B\"] = data[\"b_0_back_enc_input_embdr_0\"].T\n",
    "        bW[\"U\"] = data[\"W_back_enc_transition_0\"]\n",
    "        bW[\"Wz\"] = data[\"W_0_back_enc_update_embdr_0\"]\n",
    "        bW[\"Uz\"] = data[\"G_back_enc_transition_0\"]\n",
    "        bW[\"Wr\"] = data[\"W_0_back_enc_reset_embdr_0\"]\n",
    "        bW[\"Ur\"] = data[\"R_back_enc_transition_0\"]\n",
    "        \n",
    "        self.rnnForward  = self.RNN(fW)\n",
    "        self.rnnBackward = self.RNN(bW)\n",
    "        \n",
    "    def GetContext(self, batch):\n",
    "        batchSize, numSteps  = batch.shape\n",
    "        sourceEmbeddings = [self.embeddings.Lookup(batch[:,i]) for i in range(numSteps)]\n",
    "        statesForward  = self.rnnForward.GetContext(sourceEmbeddings)\n",
    "        statesBackward = self.rnnBackward.GetContext(sourceEmbeddings[::-1])[::-1]\n",
    "        states = np.hstack((np.vstack(statesForward),\n",
    "                            np.vstack(statesBackward)))\n",
    "        return states "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#%%writefile -a bahdanau.py\n",
    "\n",
    "class Decoder:\n",
    "    class Embeddings:\n",
    "        def __init__(self, data):\n",
    "            self.E  = data[\"W_0_dec_approx_embdr\"]\n",
    "            self.EB = data[\"b_0_dec_approx_embdr\"]\n",
    "            \n",
    "        def Initialize(self, batchSize=1):\n",
    "            return np.zeros((batchSize, self.E.shape[1]))\n",
    "        \n",
    "        def Lookup(self, i):\n",
    "            return self.E[i] + self.EB\n",
    "        \n",
    "    class RNN:\n",
    "        def __init__(self, data):\n",
    "            self.Ws  = data[\"W_0_dec_initializer_0\"]\n",
    "            self.WsB = data[\"b_0_dec_initializer_0\"].T\n",
    "\n",
    "            self.W   = data[\"W_0_dec_input_embdr_0\"]\n",
    "            self.B   = data[\"b_0_dec_input_embdr_0\"].T\n",
    "            self.U   = data[\"W_dec_transition_0\"]\n",
    "            self.C   = data[\"W_0_dec_dec_inputter_0\"]\n",
    "\n",
    "            self.Wz  = data[\"W_0_dec_update_embdr_0\"]\n",
    "            self.Uz  = data[\"G_dec_transition_0\"]\n",
    "            self.Cz  = data[\"W_0_dec_dec_updater_0\"]\n",
    "\n",
    "            self.Wr  = data[\"W_0_dec_reset_embdr_0\"]\n",
    "            self.Ur  = data[\"R_dec_transition_0\"]\n",
    "            self.Cr  = data[\"W_0_dec_dec_reseter_0\"]\n",
    "\n",
    "        def InitializeState(self, sourceContext, batchSize=1):\n",
    "            H1Backward = sourceContext[0,1000:].T\n",
    "            S0 = np.tanh(H1Backward.dot(self.Ws) + self.WsB)\n",
    "            return np.tile(S0, batchSize).reshape(batchSize, 1000)\n",
    "        \n",
    "        def GetNextState(self, embd, prevState, context):        \n",
    "            Zi = logit(embd.dot(self.Wz) + prevState.dot(self.Uz) + context.dot(self.Cz))\n",
    "            Ri = logit(embd.dot(self.Wr) + prevState.dot(self.Ur) + context.dot(self.Cr))\n",
    "            Si_= np.tanh(embd.dot(self.W) + self.B\n",
    "                          + (Ri * prevState).dot(self.U)\n",
    "                          + context.dot(self.C))\n",
    "            Si  = (1.0 - Zi) * prevState + Zi * Si_\n",
    "            return Si\n",
    "    \n",
    "    class AlignmentModel:\n",
    "        def __init__(self, data):\n",
    "            self.Va  = data[\"D_dec_transition_0\"].T\n",
    "            self.Wa  = data[\"B_dec_transition_0\"]\n",
    "            self.Ua  = data[\"A_dec_transition_0\"]\n",
    "            \n",
    "        def GetContext(self, sourceContext, prevState):\n",
    "            a = sourceContext.dot(self.Ua)\n",
    "            b = prevState.dot(self.Wa)\n",
    "            c = a.reshape(1, a.shape[0], a.shape[1]) + b.reshape(b.shape[0], 1, b.shape[1])\n",
    "            Ei = np.tensordot(self.Va, np.tanh(c).T, axes=[[1],[0]])\n",
    "            Ai = softmax(Ei, ax=1)\n",
    "            Ai = Ai.reshape(Ai.shape[1],Ai.shape[2])\n",
    "            Ci = Ai.T.dot(sourceContext)\n",
    "            return Ci\n",
    "    \n",
    "    class DeepSoftMax:\n",
    "        def __init__(self, data):\n",
    "            Wo1      = data[\"W1_dec_deep_softmax\"]\n",
    "            Wo2      = data[\"W2_dec_deep_softmax\"] \n",
    "            self.Wo  = Wo1.dot(Wo2)\n",
    "            self.WoB = data[\"b_dec_deep_softmax\"].T\n",
    "            self.Uo  = data[\"W_0_dec_hid_readout_0\"]\n",
    "            self.UoB = data[\"b_0_dec_hid_readout_0\"].T\n",
    "            self.Vo  = data[\"W_0_dec_prev_readout_0\"]\n",
    "            self.Co  = data[\"W_0_dec_repr_readout\"]\n",
    "            \n",
    "        def GetProbs(self, prevState, prevEmbd, context):\n",
    "            Ti = prevState.dot(self.Uo) + self.UoB + prevEmbd.dot(self.Vo) + context.dot(self.Co)\n",
    "            maximum = np.maximum(Ti[:,::2], Ti[:,1::2])\n",
    "            P = softmax((maximum.dot(self.Wo) + self.WoB).T)\n",
    "            logP = np.log(P)\n",
    "            return logP\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.embeddings     = self.Embeddings(data)\n",
    "        self.rnn            = self.RNN(data)\n",
    "        self.alignmentModel = self.AlignmentModel(data)\n",
    "        self.deepSoftMax    = self.DeepSoftMax(data)\n",
    "    \n",
    "    def GetScores(self, batch, mask, sourceContext):\n",
    "        states, probs = [], []\n",
    "        batchSize, numSteps  = batch.shape\n",
    "        \n",
    "        previousState = self.rnn.InitializeState(sourceContext, batchSize)\n",
    "        previousEmbedding = self.embeddings.Initialize(batchSize)\n",
    "        \n",
    "        for i in range(numSteps):\n",
    "            wordBatch = batch[:,i]\n",
    "\n",
    "            alignedSourceContext = self.alignmentModel.GetContext(sourceContext, previousState)\n",
    "\n",
    "            allProbs = self.deepSoftMax.GetProbs(previousState, previousEmbedding, alignedSourceContext)\n",
    "            \n",
    "            currentEmbedding = self.embeddings.Lookup(wordBatch)\n",
    "            currentState = self.rnn.GetNextState(currentEmbedding, previousState, alignedSourceContext)\n",
    "            \n",
    "            for column, wordId in enumerate(wordBatch):\n",
    "                #print(wordId, allProbs[wordId, column])\n",
    "                probs.append(allProbs[wordId, column]) \n",
    "            previousState, previousEmbedding = currentState, currentEmbedding\n",
    "            \n",
    "        probs = np.array(probs).reshape(numSteps, batchSize).T * mask\n",
    "        return np.sum(probs, axis=1), probs #, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#%%writefile -a bahdanau.py\n",
    "\n",
    "data = np.load(\"/home/marcinj/Badania/best_nmt/search_model.npz\")\n",
    "encoder = Encoder(data)\n",
    "decoder = Decoder(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.460252 -0.002574 -0.033437 -0.000117]] \n",
      "\n",
      "Final:  [-0.49638] \n",
      "\n",
      "Time:  1.5669\n"
     ]
    }
   ],
   "source": [
    "#%%writefile -a bahdanau.py\n",
    "\n",
    "# \"thank you . <eol>\"\n",
    "sourceSentence, mask = batchAndMask([\n",
    "        np.array([323, 22, 4, 30000])])\n",
    "\n",
    "# \"vielen dank . <eol>\"\n",
    "t1 = np.array([248, 333, 3, 30000])\n",
    "batch, mask = batchAndMask([t1])\n",
    "\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "sourceContext = encoder.GetContext(sourceSentence)\n",
    "prob, probs = decoder.GetScores(batch, mask, sourceContext)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(probs, \"\\n\")\n",
    "print(\"Final: \", prob, \"\\n\") \n",
    "\n",
    "print(\"Time: \", np.round(end - start, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Re-implementation: \n",
    "## C++ and CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin:auto\" src=\"moses-gpu.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A little code\n",
    "\n",
    "* https://github.com/emjotde/mosesdecoder/blob/nmt4/moses/FF/NMT/common/encoder.h\n",
    "* https://github.com/emjotde/mosesdecoder/blob/nmt4/moses/FF/NMT/common/decoder.h\n",
    "* https://github.com/emjotde/mosesdecoder/blob/nmt4/moses/FF/NMT/mblas/matrix.h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# moses.ini entry\n",
    "\n",
    "    NeuralScoreFeature mode=rescore name=N0\n",
    "      batch-size=1000 filtered-softmax=0\n",
    "      devices=3 num-features=2 state-length=5\n",
    "      model=/work/best_nmt/search_model.npz \n",
    "      source-vocab=/work/best_nmt/vocab/en_de.en.txt \n",
    "      target-vocab=/work/best_nmt/vocab.en_de.de.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What kb-Mira thinks:\n",
    "\n",
    "    LexicalReordering0= 0.0384 -0.0081 -0.0010 0.0672 0.0295 0.0369\n",
    "    OpSequenceModel0= 0.0245 -0.0100 -0.0089 0.0136 -0.0626\n",
    "    Distortion0= 0.0037\n",
    "    LM0= 0.0309\n",
    "    LM1= -0.0153\n",
    "    LM2= -0.0106\n",
    "    LM3= -0.0187\n",
    "    LM4= 0.0263\n",
    "    LM5= 0.0500\n",
    "    LM6= 0.0038\n",
    "    LM7= -0.0057\n",
    "    WCLM0= 0.0160\n",
    "    NeuralScoreFeature0= 0.1754 -0.0352\n",
    "    WordPenalty0= -0.0753\n",
    "    TranslationModel0= 0.0660 0.0238 0.0043 0.0028 -0.0043 0.0543 -0.0150 0.0221 0.0370 0.0010\n",
    "    UnknownWordPenalty0= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A different strategy: Stack Rescoring\n",
    "\n",
    "* Process stack ignoring the NMT Feature Function. \n",
    "* Perform recombination and to-size-pruning of stack.\n",
    "* Use NMT Feature to rescore surviving hypothesis on a per-stack basis.\n",
    "* Approximate, but allows to play around with many more hypothesis. \n",
    "* Hypothesis recombination needs to be switched off during tuning (fine for testing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## More experiments\n",
    "\n",
    "### Stand-alone\n",
    "* 21.5 (Vanilla Moses)\n",
    "* 25.6 (our Moses setup)\n",
    "* 25.8 (3-ensemble Groundhog NMT): \n",
    "\n",
    "</br>\n",
    "### Stack-based pre-calculation:\n",
    "* 27.2 (rescoring a 1000-best list)\n",
    "* 28.3 (Moses with NMT-FF with stack=30)\n",
    "\n",
    "</br>\n",
    "### Stack rescoring:\n",
    "* 28.9 (stack=2000 cube-pruning-pop-limit=5000 d=12)\n",
    "* 29.4 (2-ensemble = log-linear combination of two FFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Other languages\n",
    "\n",
    "* Planning to use the feature for WMT 16\n",
    "    * EN<->DE, EN<->RU, EN<->CS\n",
    "    * No results yet\n",
    "    * Using BPEs now for PBMT system (looks good)\n",
    "    * Can maybe report some results next week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
